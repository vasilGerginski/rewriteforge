# Server
PORT=8000
DEBUG=false

# LLM Adapter (just the name - auto-discovered from registry)
LLM_PROVIDER=mock
# LLM_PROVIDER=anthropic
# LLM_PROVIDER=openai
LLM_API_KEY=
LLM_MODEL=

# Cache Adapter (just the name - auto-discovered from registry)
CACHE_BACKEND=memory
# CACHE_BACKEND=redis
CACHE_TTL=3600
CACHE_REDIS_URL=redis://localhost:6379

# Validation
MAX_TEXT_LENGTH=5000
ALLOWED_STYLES=["pirate","haiku","formal"]
DEFAULT_STYLE=formal